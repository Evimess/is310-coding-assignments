{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanist_vols = pd.read_csv('web_scraped_humanist_listserv_volumes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Internet Era: from the start of the dataset up to and including 1998\n",
    "early_internet_era = humanist_vols[humanist_vols['inferred_start_year'] <= 1999]\n",
    "\n",
    "# Web 2.0 Era: from 1999 onwards\n",
    "web_2_0_era = humanist_vols[humanist_vols['inferred_start_year'] >= 2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlydoc = early_internet_era.volume_text.tolist()\n",
    "webdoc = web_2_0_era.volume_text.tolist()\n",
    "\n",
    "#Create a vectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=.7, min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer to our documents\n",
    "earlytransformed_documents = vectorizer.fit_transform(earlydoc)\n",
    "\n",
    "# Now get the top features for each document\n",
    "earlytransformed_documents_as_array = earlytransformed_documents.toarray()\n",
    "\n",
    "dates = early_internet_era.inferred_start_year.tolist()\n",
    "earlytfidf_results = []\n",
    "for counter, doc in enumerate(earlytransformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    one_doc_as_df['inferred_start_year'] = dates[counter]\n",
    "    earlytfidf_results.append(one_doc_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorizer to our documents\n",
    "webtransformed_documents = vectorizer.fit_transform(webdoc)\n",
    "\n",
    "# Now get the top features for each document\n",
    "webtransformed_documents_as_array = webtransformed_documents.toarray()\n",
    "\n",
    "dates = web_2_0_era.inferred_start_year.tolist()\n",
    "webtfidf_results = []\n",
    "for counter, doc in enumerate(webtransformed_documents_as_array):\n",
    "    # construct a dataframe\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), doc))\n",
    "    one_doc_as_df = pd.DataFrame.from_records(tf_idf_tuples, columns=['term', 'score']).sort_values(by='score', ascending=False).reset_index(drop=True)\n",
    "    one_doc_as_df['inferred_start_year'] = dates[counter]\n",
    "    webtfidf_results.append(one_doc_as_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>score</th>\n",
       "      <th>inferred_start_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>0.730132</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>utorepas</td>\n",
       "      <td>0.726332</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>0.721093</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>0.699473</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>0.695283</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http</td>\n",
       "      <td>0.603824</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www</td>\n",
       "      <td>0.581237</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www</td>\n",
       "      <td>0.579809</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www</td>\n",
       "      <td>0.570008</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www</td>\n",
       "      <td>0.551416</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       term     score  inferred_start_year\n",
       "0      http  0.730132                 1999\n",
       "0  utorepas  0.726332                 1987\n",
       "0      http  0.721093                 1998\n",
       "0      http  0.699473                 1997\n",
       "0      http  0.695283                 1996\n",
       "0      http  0.603824                 1995\n",
       "1       www  0.581237                 1998\n",
       "1       www  0.579809                 1997\n",
       "1       www  0.570008                 1999\n",
       "1       www  0.551416                 1995"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlytfidf_df = pd.concat(earlytfidf_results)\n",
    "earlytfidf_df = earlytfidf_df.sort_values(by=['score'], ascending=False)\n",
    "earlytfidf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>score</th>\n",
       "      <th>inferred_start_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num</td>\n",
       "      <td>0.748285</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num</td>\n",
       "      <td>0.731689</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num</td>\n",
       "      <td>0.729739</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joyent</td>\n",
       "      <td>0.692576</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num</td>\n",
       "      <td>0.689697</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joyent</td>\n",
       "      <td>0.671967</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ninch</td>\n",
       "      <td>0.657385</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.643744</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joyent</td>\n",
       "      <td>0.617716</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     term     score  inferred_start_year\n",
       "0     num  0.748285                 2004\n",
       "0     num  0.737968                 2007\n",
       "0     num  0.731689                 2003\n",
       "0     num  0.729739                 2006\n",
       "0  joyent  0.692576                 2010\n",
       "0     num  0.689697                 2005\n",
       "0  joyent  0.671967                 2011\n",
       "0   ninch  0.657385                 2002\n",
       "0    2016  0.643744                 2017\n",
       "0  joyent  0.617716                 2012"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtfidf_df = pd.concat(webtfidf_results)\n",
    "webtfidf_df = webtfidf_df.sort_values(by=['score'], ascending=False)\n",
    "webtfidf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:2975\u001b[0m, in \u001b[0;36mChart.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     copy\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mInlineData(values\u001b[39m=\u001b[39m[{}])  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Chart, copy)\u001b[39m.\u001b[39mto_dict(\n\u001b[1;32m   2973\u001b[0m         validate\u001b[39m=\u001b[39mvalidate, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, ignore\u001b[39m=\u001b[39mignore, context\u001b[39m=\u001b[39mcontext\n\u001b[1;32m   2974\u001b[0m     )\n\u001b[0;32m-> 2975\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto_dict(\n\u001b[1;32m   2976\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, ignore\u001b[39m=\u001b[39;49mignore, context\u001b[39m=\u001b[39;49mcontext\n\u001b[1;32m   2977\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:950\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m    948\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    949\u001b[0m original_data \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(copy, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, Undefined)\n\u001b[0;32m--> 950\u001b[0m copy\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m _prepare_data(original_data, context)\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m original_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Undefined:\n\u001b[1;32m    953\u001b[0m     context[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m original_data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:111\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m# convert dataframes  or objects with __geo_interface__ to dict\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39m__geo_interface__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     data \u001b[39m=\u001b[39m _pipe(data, data_transformers\u001b[39m.\u001b[39;49mget())\n\u001b[1;32m    113\u001b[0m \u001b[39m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/data.py:23\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@curried\u001b[39m\u001b[39m.\u001b[39mcurry\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_data_transformer\u001b[39m(\n\u001b[1;32m     21\u001b[0m     data: DataType, max_rows: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5000\u001b[39m\n\u001b[1;32m     22\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToValuesReturnType:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m curried\u001b[39m.\u001b[39;49mpipe(data, limit_rows(max_rows\u001b[39m=\u001b[39;49mmax_rows), to_values)\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/utils/data.py:118\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m pa_table\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m max_rows \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(values) \u001b[39m>\u001b[39m max_rows:\n\u001b[0;32m--> 118\u001b[0m     raise_max_rows_error()\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/utils/data.py:81\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_max_rows_error\u001b[39m():\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRowsError(\n\u001b[1;32m     82\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of rows in your dataset is greater \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthan the maximum allowed (\u001b[39m\u001b[39m{\u001b[39;00mmax_rows\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTry enabling the VegaFusion data transformer which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraises this limit by pre-evaluating data\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtransformations in Python.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m    >> import altair as alt\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m    >> alt.data_transformers.enable(\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvegafusion\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOr, see https://altair-viz.github.io/user_guide/large_datasets.html \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor additional information\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon how to plot large datasets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m     )\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "chart = alt.Chart(earlytfidf_df).mark_bar().encode(\n",
    "    y='score',\n",
    "    x='inferred_start_year:T',\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(earlytfidf_df['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'score', 'year(inferred_start_year)'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 10 Terms by TF-IDF Score in Humanist Volumes'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_terms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top_terms[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtop_terms\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m      2\u001b[0m selection \u001b[38;5;241m=\u001b[39m alt\u001b[38;5;241m.\u001b[39mselection_point(fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mterm\u001b[39m\u001b[38;5;124m'\u001b[39m], bind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlegend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m chart \u001b[38;5;241m=\u001b[39m alt\u001b[38;5;241m.\u001b[39mChart(top_terms)\u001b[38;5;241m.\u001b[39mmark_bar()\u001b[38;5;241m.\u001b[39mencode(\n\u001b[1;32m      4\u001b[0m     y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     x\u001b[38;5;241m=\u001b[39malt\u001b[38;5;241m.\u001b[39mX(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperiod\u001b[39m\u001b[38;5;124m'\u001b[39m, sort\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_internet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweb_2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontemporary\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39malt\u001b[38;5;241m.\u001b[39mAxis(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPeriod\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop 30 Terms by TF-IDF Score in Humanist Volumes by Period\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'top_terms' is not defined"
     ]
    }
   ],
   "source": [
    "top_terms['period'] = top_terms['period'].astype(str)\n",
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "chart = alt.Chart(top_terms).mark_bar().encode(\n",
    "    y='score',\n",
    "    x=alt.X('period', sort=['early_internet', 'web_2.0', 'contemporary'], axis=alt.Axis(title='Period')),\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(top_terms['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'score', 'period'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 30 Terms by TF-IDF Score in Humanist Volumes by Period'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxRowsError",
     "evalue": "The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMaxRowsError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:2975\u001b[0m, in \u001b[0;36mChart.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m   2971\u001b[0m     copy\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mInlineData(values\u001b[39m=\u001b[39m[{}])  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(Chart, copy)\u001b[39m.\u001b[39mto_dict(\n\u001b[1;32m   2973\u001b[0m         validate\u001b[39m=\u001b[39mvalidate, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, ignore\u001b[39m=\u001b[39mignore, context\u001b[39m=\u001b[39mcontext\n\u001b[1;32m   2974\u001b[0m     )\n\u001b[0;32m-> 2975\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mto_dict(\n\u001b[1;32m   2976\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, ignore\u001b[39m=\u001b[39;49mignore, context\u001b[39m=\u001b[39;49mcontext\n\u001b[1;32m   2977\u001b[0m )\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:950\u001b[0m, in \u001b[0;36mTopLevelMixin.to_dict\u001b[0;34m(self, validate, format, ignore, context)\u001b[0m\n\u001b[1;32m    948\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    949\u001b[0m original_data \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(copy, \u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, Undefined)\n\u001b[0;32m--> 950\u001b[0m copy\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m _prepare_data(original_data, context)\n\u001b[1;32m    952\u001b[0m \u001b[39mif\u001b[39;00m original_data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m Undefined:\n\u001b[1;32m    953\u001b[0m     context[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m original_data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/v5/api.py:111\u001b[0m, in \u001b[0;36m_prepare_data\u001b[0;34m(data, context)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m# convert dataframes  or objects with __geo_interface__ to dict\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, pd\u001b[39m.\u001b[39mDataFrame) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(data, \u001b[39m\"\u001b[39m\u001b[39m__geo_interface__\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 111\u001b[0m     data \u001b[39m=\u001b[39m _pipe(data, data_transformers\u001b[39m.\u001b[39;49mget())\n\u001b[1;32m    113\u001b[0m \u001b[39m# convert string input to a URLData\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/vegalite/data.py:23\u001b[0m, in \u001b[0;36mdefault_data_transformer\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m@curried\u001b[39m\u001b[39m.\u001b[39mcurry\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_data_transformer\u001b[39m(\n\u001b[1;32m     21\u001b[0m     data: DataType, max_rows: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5000\u001b[39m\n\u001b[1;32m     22\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToValuesReturnType:\n\u001b[0;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m curried\u001b[39m.\u001b[39;49mpipe(data, limit_rows(max_rows\u001b[39m=\u001b[39;49mmax_rows), to_values)\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[39mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[39m=\u001b[39m func(data)\n\u001b[1;32m    629\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/toolz/functoolz.py:304\u001b[0m, in \u001b[0;36mcurry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    303\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    305\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_curry(args, kwargs, exc):\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/utils/data.py:118\u001b[0m, in \u001b[0;36mlimit_rows\u001b[0;34m(data, max_rows)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[39mreturn\u001b[39;00m pa_table\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m max_rows \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(values) \u001b[39m>\u001b[39m max_rows:\n\u001b[0;32m--> 118\u001b[0m     raise_max_rows_error()\n\u001b[1;32m    120\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.virtualenvs/is310-env/lib/python3.11/site-packages/altair/utils/data.py:81\u001b[0m, in \u001b[0;36mlimit_rows.<locals>.raise_max_rows_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_max_rows_error\u001b[39m():\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRowsError(\n\u001b[1;32m     82\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe number of rows in your dataset is greater \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mthan the maximum allowed (\u001b[39m\u001b[39m{\u001b[39;00mmax_rows\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTry enabling the VegaFusion data transformer which \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mraises this limit by pre-evaluating data\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtransformations in Python.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m    >> import altair as alt\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m    >> alt.data_transformers.enable(\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvegafusion\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOr, see https://altair-viz.github.io/user_guide/large_datasets.html \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfor additional information\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon how to plot large datasets.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m     )\n",
      "\u001b[0;31mMaxRowsError\u001b[0m: The number of rows in your dataset is greater than the maximum allowed (5000).\n\nTry enabling the VegaFusion data transformer which raises this limit by pre-evaluating data\ntransformations in Python.\n    >> import altair as alt\n    >> alt.data_transformers.enable(\"vegafusion\")\n\nOr, see https://altair-viz.github.io/user_guide/large_datasets.html for additional information\non how to plot large datasets."
     ]
    },
    {
     "data": {
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = alt.selection_point(fields=['term'], bind='legend')\n",
    "chart = alt.Chart(webtfidf_df).mark_bar().encode(\n",
    "    y='score',\n",
    "    x='inferred_start_year:T',\n",
    "    color=alt.Color('term', legend=alt.Legend(title='Term', orient='right', symbolLimit=len(webtfidf_df['term'].unique()), columns=5), scale=alt.Scale(scheme='tableau20')),\n",
    "    tooltip=['term', 'score', 'year(inferred_start_year)'],\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(selection).properties(\n",
    "    title='Top 10 Terms by TF-IDF Score in Humanist Volumes'\n",
    ")\n",
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('is310-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a8c5e5bf18a501e79dfa30e93ed5c02b8c8ccfee1fc9fd1d32c6e050f34f6f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
